# StructifyAI Visualizer

This project is a web-based application for visualizing and processing floor plan images. It uses a React frontend to provide a user interface for uploading floor plans, and a Python backend to process the images using machine learning models.

## Features

-   **Floor Plan Upload:** Upload floor plan images (PNG, JPG) for processing.
-   **AI-Powered Analysis:** The backend uses YOLO models to identify and segment walls, rooms, and objects in the floor plan.
-   **Multiple Output Formats:** Generates annotated images, GeoJSON files with polygonal data, and a 3D IFC model of the floor plan.
-   **Interactive Visualization:** The frontend displays the processed results, including annotated images and interactive model viewers.

## Technologies Used

**Frontend:**

-   [Vite](https://vitejs.dev/)
-   [React](https://reactjs.org/)
-   [TypeScript](https://www.typescriptlang.org/)
-   [Tailwind CSS](https://tailwindcss.com/)
-   [shadcn-ui](https://ui.shadcn.com/)

**Backend:**

-   [FastAPI](https://fastapi.tiangolo.com/)
-   [YOLO (ultralytics)](https://ultralytics.com/)
-   [OpenCV](https://opencv.org/)
-   [Shapely](https://shapely.readthedocs.io/en/stable/manual.html)
-   [ifcopenshell](http://ifcopenshell.org/)
-   [ngrok](https://ngrok.com/)

## Getting Started

Follow these steps to set up and run the project on your local machine.

### 1. Clone the Repository

First, clone the project repository from GitHub:

```bash
git clone https://github.com/ankush-10010/structify-visualizer-ai.git
cd https://github.com/ankush-10010/structify-visualizer-ai.git
```

### 2. Set Up the Backend

The backend is a Python script that uses FastAPI to create an API for processing floor plan images. You can run it either in a Google Colab notebook or on your local machine.

**Option A: Running in Google Colab (Recommended)**

1.  **Open `backend.py` in Google Colab.**
2.  **Mount Google Drive:** The script is configured to load the pre-trained models from Google Drive. Make sure to upload the models to the specified path (`/content/drive/MyDrive/Trained_Model/`).
3.  **Install Dependencies:** Run the following command in a Colab cell to install the required Python libraries:
    ```bash
    pip install ultralytics shapely opencv-python matplotlib geojson ifcopenshell tqdm pyngrok fastapi uvicorn python-multipart nest_asyncio
    ```
4.  **Set ngrok Authtoken:** You will need an ngrok account to expose the backend service. Replace `'YOUR_NGROK_AUTHTOKEN'` in the script with your actual token.
    ```python
    !ngrok authtoken YOUR_NGROK_AUTHTOKEN
    ```
5.  **Run the Backend:** Execute the script. It will start the FastAPI server and provide a public ngrok URL.

**Option B: Running Locally**

1.  **Install Dependencies:**
    ```bash
    pip install ultralytics shapely opencv-python matplotlib geojson ifcopenshell tqdm pyngrok fastapi uvicorn python-multipart nest_asyncio
    ```
2.  **Download Models:** Make sure you have the pre-trained models (`wall_segmentor.pt` and `image_segmentor.pt`) and update the paths in `backend.py` to point to their location on your local machine.
3.  **Set ngrok Authtoken:** Configure your ngrok authtoken by running:
    ```bash
    ngrok authtoken YOUR_NGROK_AUTHTOKEN
    ```
4.  **Run the Backend:**
    ```bash
    python backend.py
    ```
    This will start the server and provide a public ngrok URL.

### 3. Configure the Frontend

Once the backend is running, you need to connect the frontend to it.

1.  **Get the Backend URL:** Copy the public URL generated by ngrok (e.g., `https://<unique-id>.ngrok-free.app`).
2.  **Update Frontend Configuration:** Open the `src/backend.ts` file and paste the ngrok URL as the value for `API_BASE_URL`.

    ```typescript
    // src/backend.ts
    const API_BASE_URL = 'https://<your-ngrok-url>'; // <-- Paste your URL here
    ```

### 4. Run the Frontend

1.  **Install Dependencies:**
    ```bash
    npm install --force
    ```
2.  **Start the Development Server:**
    ```bash
    npm run dev
    ```
    This will start the Vite development server, and you can access the application in your browser at `http://localhost:5173`.

## How to Use the Application

1.  **Upload an Image:** Drag and drop a floor plan image onto the upload zone or click to select a file.
2.  **Processing:** The image will be sent to the backend for processing. This may take a few moments.
3.  **View Results:** Once processing is complete, the frontend will display the results, including:
    -   Annotated images showing detected walls, rooms, and objects.
    -   An interactive 3D model of the floor plan.
    -   A downloadable ZIP file containing all the generated artifacts.

## Deploying the Project

You can deploy the frontend using any static hosting service (e.g., Vercel, Netlify, GitHub Pages). For the backend, you will need a server or a serverless environment to run the Python script.

---

This `README.md` provides a comprehensive guide to setting up and running the StructifyAI Visualizer project. If you encounter any issues, please refer to the documentation of the respective technologies used in the project.
